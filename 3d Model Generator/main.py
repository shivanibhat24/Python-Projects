"""
AI-Powered 3D Model Generator
----------------------------
This application uses a combination of Stable Diffusion, NeRF, and Blender
to generate 3D models from text prompts.

Requirements:
- Python 3.9+
- PyTorch
- Stable Diffusion
- Blender Python API
- nerfacto
- diffusers
"""

import os
import argparse
import torch
import numpy as np
from pathlib import Path
from PIL import Image
import subprocess
import json
import time
from typing import List, Dict, Any, Tuple, Optional

# Diffusers for text-to-image generation
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

# For NeRF processing
try:
    from nerfstudio.pipelines.base_pipeline import Pipeline as NeRFPipeline
    from nerfstudio.data.dataparsers.instant_ngp_dataparser import InstantNGPDataParser
    from nerfstudio.models.nerfacto import NerfactoModel
    from nerfstudio.cameras.cameras import Cameras
except ImportError:
    print("NeRF libraries not found. Installing required packages...")
    subprocess.run(["pip", "install", "nerfstudio"], check=True)
    # After installation, retry imports
    from nerfstudio.pipelines.base_pipeline import Pipeline as NeRFPipeline
    from nerfstudio.data.dataparsers.instant_ngp_dataparser import InstantNGPDataParser
    from nerfstudio.models.nerfacto import NerfactoModel
    from nerfstudio.cameras.cameras import Cameras

class TextTo3DGenerator:
    """Main class for generating 3D models from text prompts."""
    
    def __init__(self, output_dir: str = "output", device: str = None):
        """Initialize the generator.
        
        Args:
            output_dir: Directory to save intermediate and final outputs
            device: Device to run models on ('cuda' or 'cpu')
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        # Images directory for multi-view generation
        self.images_dir = self.output_dir / "images"
        self.images_dir.mkdir(exist_ok=True)
        
        # NeRF outputs directory
        self.nerf_dir = self.output_dir / "nerf"
        self.nerf_dir.mkdir(exist_ok=True)
        
        # Final models directory
        self.models_dir = self.output_dir / "models"
        self.models_dir.mkdir(exist_ok=True)
        
        # Set device (GPU if available, otherwise CPU)
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        print(f"Using device: {self.device}")
        
        # Load Stable Diffusion model
        self._load_stable_diffusion()
        
    def _load_stable_diffusion(self):
        """Load the Stable Diffusion model."""
        model_id = "stabilityai/stable-diffusion-2-1"
        
        # Initialize the pipeline with better scheduler
        self.text_to_image = StableDiffusionPipeline.from_pretrained(
            model_id, 
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        )
        
        # Use more efficient scheduler
        self.text_to_image.scheduler = DPMSolverMultistepScheduler.from_config(
            self.text_to_image.scheduler.config
        )
        
        # Move to device and enable memory optimization if on GPU
        self.text_to_image = self.text_to_image.to(self.device)
        if self.device == "cuda":
            self.text_to_image.enable_attention_slicing()
    
    def generate_multi_view_images(self, prompt: str, num_views: int = 8, 
                                  image_size: int = 512, guidance_scale: float = 7.5) -> List[Path]:
        """Generate multiple views of the object based on text prompt.
        
        Args:
            prompt: Text description of the object to generate
            num_views: Number of views to generate around the object
            image_size: Size of the generated images
            guidance_scale: Guidance scale for Stable Diffusion
            
        Returns:
            List of paths to generated images
        """
        print(f"Generating {num_views} views for prompt: '{prompt}'")
        
        # Create subdirectory for this specific prompt
        prompt_slug = "_".join(prompt.lower().split()[:5])
        prompt_dir = self.images_dir / prompt_slug
        prompt_dir.mkdir(exist_ok=True)
        
        image_paths = []
        
        # Generate images from different viewpoints
        for i in range(num_views):
            # Calculate angle for this view (in degrees, around y-axis)
            angle = (i / num_views) * 360
            
            # Modify prompt to specify viewpoint
            view_prompt = f"{prompt}, from {angle} degree angle, 3D render, high quality, detailed"
            
            # Generate image
            image = self.text_to_image(
                view_prompt, 
                height=image_size,
                width=image_size,
                num_inference_steps=30,
                guidance_scale=guidance_scale
            ).images[0]
            
            # Save image
            image_path = prompt_dir / f"view_{i:03d}_{angle:.1f}deg.png"
            image.save(image_path)
            image_paths.append(image_path)
            
            print(f"  Generated view {i+1}/{num_views} at {angle:.1f}Â° angle")
            
        return image_paths
            
    def process_nerf(self, image_paths: List[Path], prompt: str) -> Path:
        """Process images with NeRF to create a 3D representation.
        
        Args:
            image_paths: List of paths to the multi-view images
            prompt: Original text prompt (used for naming)
            
        Returns:
            Path to the generated NeRF model directory
        """
        print("Initializing NeRF processing...")
        
        # Create config for NeRF
        prompt_slug = "_".join(prompt.lower().split()[:5])
        nerf_output_dir = self.nerf_dir / prompt_slug
        nerf_output_dir.mkdir(exist_ok=True)
        
        # Create camera parameters file for the images
        camera_params = self._create_camera_params(image_paths)
        camera_file = nerf_output_dir / "cameras.json"
        with open(camera_file, 'w') as f:
            json.dump(camera_params, f, indent=2)
            
        print(f"Camera parameters saved to {camera_file}")
        
        # Set up NeRF configuration
        config = {
            "data": {
                "parser": "instant_ngp",
                "camera_path": str(camera_file),
                "images_path": str(self.images_dir / prompt_slug)
            },
            "model": {
                "type": "nerfacto",
                "background_color": "white"
            },
            "trainer": {
                "max_num_iterations": 5000,
                "steps_per_eval": 500
            },
            "pipeline": {
                "datamanager": {
                    "camera_optimizer": {
                        "mode": "off"
                    }
                }
            }
        }
        
        # Save config
        config_path = nerf_output_dir / "config.json"
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
            
        # Run NeRF training (this is a simplified version - in practice, you'd use nerfstudio's CLI)
        print("Training NeRF model (this may take a while)...")
        
        try:
            # In a real implementation, we'd directly use the nerfstudio Python API
            # Here we use the CLI for simplicity
            cmd = [
                "ns-train", 
                "nerfacto",
                "--data", str(self.images_dir / prompt_slug),
                "--output-dir", str(nerf_output_dir),
                "--max-num-iterations", "5000"
            ]
            
            print(f"Running command: {' '.join(cmd)}")
            subprocess.run(cmd, check=True)
            
            print(f"NeRF model trained and saved to {nerf_output_dir}")
            return nerf_output_dir
            
        except (subprocess.SubprocessError, FileNotFoundError) as e:
            print(f"Error running NeRF training: {e}")
            print("Continuing with mock NeRF output for demonstration")
            
            # Create mock output for demonstration
            mock_output_file = nerf_output_dir / "point_cloud.ply"
            with open(mock_output_file, 'w') as f:
                f.write("# Mock NeRF point cloud output\n")
                
            return nerf_output_dir
            
    def _create_camera_params(self, image_paths: List[Path]) -> Dict[str, Any]:
        """Create camera parameters for NeRF based on the generated views.
        
        Args:
            image_paths: List of paths to the multi-view images
            
        Returns:
            Camera parameters dictionary
        """
        num_views = len(image_paths)
        cameras = {}
        
        # Calculate camera positions around a circle
        radius = 2.0  # Distance from center
        for i, img_path in enumerate(image_paths):
            # Extract angle from filename
            angle_str = img_path.stem.split('_')[-1].replace('deg', '')
            try:
                angle = float(angle_str)
            except ValueError:
                angle = (i / num_views) * 360
                
            # Convert to radians
            angle_rad = np.radians(angle)
            
            # Camera position (on a circle around y-axis)
            cam_pos = [
                radius * np.sin(angle_rad),  # x
                0.0,                         # y
                radius * np.cos(angle_rad)   # z
            ]
            
            # Camera is looking at origin
            look_at = [0.0, 0.0, 0.0]
            
            # Calculate view direction
            view_dir = np.array(look_at) - np.array(cam_pos)
            view_dir = view_dir / np.linalg.norm(view_dir)
            
            # Camera up direction (usually positive y)
            up = [0.0, 1.0, 0.0]
            
            # Camera parameters for this view
            cameras[str(i)] = {
                "resolution": [512, 512],
                "camera_to_world": self._look_at_to_matrix(cam_pos, look_at, up),
                "intrinsics": {
                    "fx": 256.0,  # focal length in x
                    "fy": 256.0,  # focal length in y
                    "cx": 256.0,  # principal point x
                    "cy": 256.0   # principal point y
                }
            }
            
        return {"cameras": cameras}
    
    def _look_at_to_matrix(self, eye: List[float], target: List[float], up: List[float]) -> List[List[float]]:
        """Create a camera-to-world transformation matrix from eye, target and up vectors.
        
        Args:
            eye: Camera position
            target: Point camera is looking at
            up: Up direction
            
        Returns:
            4x4 camera-to-world matrix as a list of lists
        """
        # Convert inputs to numpy arrays
        eye = np.array(eye)
        target = np.array(target)
        up = np.array(up)
        
        # Calculate camera axes
        forward = target - eye
        forward = forward / np.linalg.norm(forward)
        
        right = np.cross(forward, up)
        right = right / np.linalg.norm(right)
        
        up = np.cross(right, forward)
        
        # Create rotation matrix (transposed because we're going from camera to world)
        rotation = np.array([
            [right[0], up[0], -forward[0]],
            [right[1], up[1], -forward[1]],
            [right[2], up[2], -forward[2]]
        ])
        
        # Create 4x4 transformation matrix
        transform = np.eye(4)
        transform[:3, :3] = rotation
        transform[:3, 3] = eye
        
        # Convert to list of lists and return
        return transform.tolist()
            
    def convert_to_mesh(self, nerf_dir: Path, prompt: str) -> Path:
        """Convert NeRF model to a 3D mesh using Blender.
        
        Args:
            nerf_dir: Directory containing the NeRF model
            prompt: Original text prompt (used for naming)
            
        Returns:
            Path to the final 3D model file
        """
        print("Converting NeRF representation to mesh...")
        
        # For this example, we'll use a simplified version that calls a Blender Python script
        prompt_slug = "_".join(prompt.lower().split()[:5])
        output_file = self.models_dir / f"{prompt_slug}.obj"
        
        # Create a Blender Python script that will convert the NeRF to mesh
        blender_script = self.output_dir / "blender_convert.py"
        
        with open(blender_script, 'w') as f:
            f.write(f"""
import bpy
import os
import sys
import numpy as np

# Clear existing objects
bpy.ops.object.select_all(action='SELECT')
bpy.ops.object.delete()

# Path to the NeRF data (point cloud or mesh)
nerf_path = "{nerf_dir}"
output_path = "{output_file}"

# For demonstration, create a simple mesh based on the prompt
# In a real implementation, this would load and process the NeRF output
prompt = "{prompt}"

if "sphere" in prompt.lower():
    bpy.ops.mesh.primitive_uv_sphere_add(radius=1.0)
elif "cube" in prompt.lower():
    bpy.ops.mesh.primitive_cube_add(size=1.0)
elif "cylinder" in prompt.lower():
    bpy.ops.mesh.primitive_cylinder_add(radius=0.5, depth=2.0)
else:
    # Default to a smooth mesh resembling typical NeRF output
    bpy.ops.mesh.primitive_ico_sphere_add(radius=1.0, subdivisions=3)
    
    # Apply a displacement modifier with noise to make it more organic
    obj = bpy.context.active_object
    mod = obj.modifiers.new(name="Displace", type='DISPLACE')
    
    # Create a noise texture
    tex = bpy.data.textures.new("Displacement", type='CLOUDS')
    tex.noise_scale = 0.5
    
    mod.texture = tex
    mod.strength = 0.2
    
    # Apply subdivision for smoother result
    subsurf = obj.modifiers.new(name="Subsurf", type='SUBSURF')
    subsurf.levels = 2
    
    # Apply modifiers
    bpy.ops.object.modifier_apply(modifier=subsurf.name)
    bpy.ops.object.modifier_apply(modifier=mod.name)

# Export as OBJ
bpy.ops.export_scene.obj(filepath=output_path)
print(f"Exported mesh to {output_path}")
""")
        
        # Run Blender with the script
        try:
            blender_cmd = ["blender", "--background", "--python", str(blender_script)]
            print(f"Running Blender with command: {' '.join(blender_cmd)}")
            
            subprocess.run(blender_cmd, check=True)
            print(f"3D model exported to {output_file}")
            
        except (subprocess.SubprocessError, FileNotFoundError) as e:
            print(f"Error running Blender: {e}")
            print("Creating a placeholder OBJ file")
            
            # Create a simple placeholder OBJ file
            with open(output_file, 'w') as f:
                f.write(f"""
# Placeholder OBJ for "{prompt}"
# In a real implementation, this would be generated by Blender
v 1.0 0.0 0.0
v 0.0 1.0 0.0
v 0.0 0.0 1.0
v 0.0 0.0 0.0
f 1 2 3
f 1 3 4
f 1 4 2
f 2 4 3
""")
                
        return output_file
    
    def generate_3d_model(self, prompt: str, num_views: int = 12) -> Path:
        """Generate a 3D model from a text prompt.
        
        Args:
            prompt: Text description of the 3D model to generate
            num_views: Number of views to generate
            
        Returns:
            Path to the final 3D model file
        """
        print(f"\n=== Generating 3D model for: '{prompt}' ===\n")
        
        # 1. Generate multi-view images
        image_paths = self.generate_multi_view_images(prompt, num_views=num_views)
        
        # 2. Process with NeRF
        nerf_dir = self.process_nerf(image_paths, prompt)
        
        # 3. Convert to mesh using Blender
        model_path = self.convert_to_mesh(nerf_dir, prompt)
        
        print(f"\n=== 3D model generation complete ===")
        print(f"Final model saved to: {model_path}")
        
        return model_path

# CLI interface
def main():
    parser = argparse.ArgumentParser(description="Generate 3D models from text prompts using AI")
    parser.add_argument("prompt", type=str, help="Text description of the 3D model to generate")
    parser.add_argument("--output-dir", "-o", type=str, default="output", 
                        help="Directory to save outputs")
    parser.add_argument("--views", "-v", type=int, default=8,
                        help="Number of views to generate (default: 8)")
    parser.add_argument("--device", "-d", type=str, choices=["cuda", "cpu"], 
                        help="Device to use (default: auto-detect)")
    
    args = parser.parse_args()
    
    # Create generator
    generator = TextTo3DGenerator(output_dir=args.output_dir, device=args.device)
    
    # Generate 3D model
    model_path = generator.generate_3d_model(args.prompt, num_views=args.views)
    
    print(f"\nModel generated successfully: {model_path}")
    
if __name__ == "__main__":
    main()
